---
title: "Analysis of Class Surveys"
subtitle: "PSTAT 197 Fall 2025"
author: "Aiden, Oscar, Eitan, Sam, and Phillip"
date: last-modified
published-title: "Updated"
editor: visual
format: html
code-copy: true
execute:
  message: false
  warning: false
  echo: false
  cache: true
---

## Executive summary

This project analyzed survey data from 60 students enrolled in PSTAT197A to explore how coursework, programming language preference, and self-reported comfort and proficiency relate to one another. Our findings show that most students prefer Python, particularly those interested in industry-focused projects, while R remains more common among students pursuing statistically oriented or research-based paths. Course-level analysis revealed that students who completed CS130 (Data Structures and Algorithms) and PSTAT131 (Machine Learning) tend to show stronger interests in applied topics such as deep learning and predictive modeling, whereas PSTAT120 (Statistics) students focus more on inference and theory. We also found that greater depth in upper-division coursework is associated with higher comfort and proficiency, especially in statistics. Finally, a significant positive correlation between comfort and proficiency across all subjects confirms that students who feel more skilled in a topic also report greater confidence in it. Overall, the analysis highlights meaningful links between curriculum choices, technical interests, and perceived ability within the data science student community.

## Data description

Our data set was a class survey that was distributed to all students offered enrollment in PSTAT197A for Fall 2025. The survey recorded 60 responses and was taken anonymously through Google Forms. The survey asked about several aspects of a student's background, including their major, year, areas of interests, classes taken, programming language proficiency, etc. These questions were in the form of multiple choice and allowed students to pick all selections that apply to them.

Before conducting our analysis, we combined two separate data files—`background-clean.csv` and `interest-clean.csv`—which contained complementary survey information. These were merged by `response_id` using an inner join to ensure that only complete responses present in both datasets were included. This process produced a single, cleaned dataset used for all subsequent analysis.

This step was essential because many parts of our analysis require information from both the background and interest surveys. The merged dataset therefore served as the foundation for all the visualizations and correlations presented later in the report.

## Questions of interest

Our goal in the analysis of the class survey data was to explore the preference of different programming languages and how it relates to the students' desired field of interest and domains. Additionally, we also wanted to explore any relationships between the types of courses taken by students and their experience with different programming languages, as well as how their major affects this. In this report, we will be answering the following questions:

1.  Does programming language preference (Python or R) relate to the type of projects a student would want to work on (Lab or Industry) as well as their desired field of interest?

2.  How do the courses a student takes within a subject affect their Statistical, Math, and Programming comfortability/proficiency?

3.  Is there a correlation between comfort level and proficiency level for each skill?

## Findings

### Question 1:

In order to investigate our question, we first need to know the counts for each language. Our initial analysis showed that majority of students preferred using Python as their default programming language. Additionally, the rest of the students either put they had no preference or used R instead. The plot below shows the counts for each programming language.

![](images/Programming%20Language%20Preferece%20Counts.png)

Next, we created a plot to show the relationship between students language preference between Python and R as it relates to what type of capstone project they wanted to do, with the options being industry, lab, or both/no preference. The vast majority of responses are from students who want to work on an industry project in Python. This makes intuitive sense because I would say on average statistics majors are focused on landing a job post graduation, and a project in the data science industry usually uses Python as the standard language, meaning that this would be the most transferrable project. The fact that those who picked both preferred is curious, because we normally associate R with lab work, or at least definitely lab and coursework at UCSB.

![](images/Language%20Preference%20by%20Project%20Type.png)

Our next two plots show the domain of interest for students relative to the research area they are interested. In the survey the question was phrased as "what area of data science are of interest to you", however we grouped them into stats and tech because a handful of topics were more CS/Software oriented. The classes are as follows, "Stats/Research Statistical models and inference", "Predictive modeling", "Spatial statistics or time series analysis", "Natural language processing and analysis of text", "Algorithms", "Data visualization and interactive dashboards" vs Tech: "Model deployment and software or web integrations", "Data acquisition and engineering","Backend" "Deep learning and neural networks", "Analysis or classification of images".

The second plot considers deep learning and analysis/classification of images as a Statistics category, because there is an active debate between what is Computer Science vs Statistics vs Data science (which usually tends to be the intersection of a Stats and CS diagram). What we see is that clearly neural networks and image classification are very popular as they are able to change the proportion of research interest in different domains by around forty percent. This intuitively makes sense, as neural networks in particularly represent the hot new technology that everyone is trying to understand, and a year long research class is the perfect place to enhance one's understanding in that field while also building an impressive project.

|  |  |
|------------------------------------|------------------------------------|
| ![](images/Domain%20of%20Interest%20(1)-01.png) | ![](images/Domain%20of%20Interest%20(2)-01.png) |

In addition to this, we also investigated the most common interests reported by students as well as by classes taken. From this analysis, we created the following two plots:

![](images/Interests%20Counts-01.png)

Students who completed CS130 and PSTAT131 show stronger interests in applied topics such as deep learning, predictive modeling, and model deployment, indicating these courses attract technically oriented learners. In contrast, PSTAT120 students emphasize statistical modeling and inference, reflecting a more analytical focus. CS16 students show balanced interests across areas, suggesting it serves as an early, general foundation before specialization.

![](images/Interests%20Chart-01.png)

Lastly, we also decided to look at language preference by classes taken. It turns out most people in the class (all but 3) have taken 2 Computer Science classes, so I decided to break it up by PSTAT class. We found this interesting because for the most part, UCSB PSTAT Classes are taught in R. That intuition suggests that the more PSTAT classes you take the more you would prefer R. However, there are several possibilities that can contribute to this result. We saw previously people mainly want to do a Python project in the industry, so it can also be true that the more PSTAT classes you take the more you are thinking about getting a project in the industry. It is also true that in general students may see Python as a future career skill.

![](images/Programming%20Languages%20by%20Courses.png)

------------------------------------------------------------------------

### Question 2:

To gain a basis understanding of the relationship between total courses and upper division, we first created multiple plots to demonstrate how they relate with each and how many courses most students have taken. In this first plot, rows are the upper-division (UD) buckets from updv.num (0–2, 3–5, 6–8, 9+), and the columns are created buckets of total courses checked off (0–2, 3–5, 6–8, 9+). What we can observe from this plot is the mass is strongly diagonal, the higher total buckets pair well with higher UD buckets, with large within-column shares in the matching. So we can conclude that the total and UD measures are consistent both very consistent measures. Thus, in the plots and analysis to come we see that we can use either bucket, and it suggests UD captures depth rather than just quantity, which can also be concluded from the data collection where updv.num can account for more math and stats and CS classes than the totals which were limited to only what we were able to check off.

## ![](images/Total%20Course%20Buckets%20vs%20Upper%20Division%20Buckets.png)

In plot 2 for the Stat/Prog/Math, each total-course bucket is split into beg/int/adv in relation to proficiency which were marked on the intake forms. In the plot we can see that as total courses increase, beg shrinks and adv grows in all three fields, this gradient is most apparent in Statistics, moderate in Math, and weaker in Programming (where many students are already “adv/int” at the low totals). This plot validates the idea that the more coursework which is done the more likely someone is to believe that they have a higher proficiency in the respective fields.

Plot 3 follows the exact same ideas and principles as plot 2; however, this is using the number of upper divisions one has taken instead of the total courses which could be checked. There is a different result found though. While we observe similar results to plot 2 they are far less dramatic and this could be for numerous reasons, but it is more likely that with the removal of the inclusion of specific class which could help in proficiency that one may put a lower score. Many factors could cause for this difference. But, we can conclude that upper division counts show better indications of depth in the data set.

|  |  |
|-------------------------------------|-----------------------------------|
| ![](images/Proficiency%20across%20Total-01.png) | ![](images/Proficiency%20Across%20UD-01.png) |

In the below plots 4 and 5 we are measuring the same thing within both, however they just provided different visuals for us to analyze. Now my group has deduced that comfort rating is a better indicator of ability within respective fields. In these plots we additionally have not measured math because there is no inclusion of math department courses so we can not run this analysis on math comfort rating.

\
In these plots of courses which have been taken in CS and PSTAT that were able to be checked off in the intake survey and plotted them against ones comfort rating in programming and statistics respectively. We observe that the plots model: student department-specific counts (x) vs matching comfort (y), faceted for CS→Prog and PSTAT→Stat. Additionally we observe that both slopes are positive. The PSTAT→Stat slope is steeper: more PSTAT courses is closely associated with higher Stat comfort. The CS→Prog slope is positive but flatter. Now from these plots we can conclude that more within-subject courses implies higher comfort is clearly true for Statistics and present but weaker for Programming, likely because programming comfort comes from PSTAT/R work, prior experience, and self-study—not just CS courses.

Specifically within plot 5 we can see in the comparison of CS courses with programming that there is a heavy concentration around x=1 with y of about 3–4. While in PSTAT courses relation with statistical comfort, the mass sits at x of about 4–6 with y=4–5, plus a thin tail at higher x with y=5.

|  |  |
|---------------------------------------|---------------------------------|
| ![](images/Course%20Counts%20vs%20Comfort%20(Jitter)-01.png) | ![](images/Course%20Counts%20vs%20Comfort-01.png) |

Much like plots 4 and 5 these two plots are of the same information however are different visuals. In plot 6 we see UD bucket on x, comfort on y, with a per-bucket mean line. We observe from this plot that the mean line rises with UD buckets for all fields. Largest for stats, moderate for math, and lowest for programming. These findings do not suprise me at all because this means having learned from more classes leads to an increase of comfort in such field. Thus we can conclude that comfort increases with depth of coursework, reinforcing the department-specific results above.

Now for plot 7 we see the counts at each UD bucket × comfort rating cell, per field on y. We see for Statistics, high counts concentrate at (6–8, 4–5) and (9+, 4–5). Programming shows many 4’s (and some 5’s) even at 0–2/3–5. Math shows a slow increase toward higher comfort in higher UD buckets. Thus, we reinforce our findings from plot 6.

|  |  |
|--------------------------------|---------------------------------------|
| ![](images/UD%20Buckets%20vs%20Comfort.png) | ![](images/UD%20Buckets%20vs%20Comfort%20(counts).png) |

In plot 8 we see that for each field, UD buckets are structured into comfort levels 1–5. We observe a shared shift upward with UD buckets i.e. lower comfort shrinks, higher comfort grows. The shift is most pronounced for Stat, then Math and lastly for Programming it still trends upward but maintains a large high-comfort share even at low UD. Thus, we have found that the distributional view supports the same conclusions we have made so far that the depth of UD course buckets tracks comfort best.

![](images/Comfort%20Across%20UD.png)

------------------------------------------------------------------------

### Question 3:

Before we began analyzing the relationship between comfort level and proficiency level for Programming, Statistics, and Math, we first created plots to visualize the current standing of the students. The following plots show the respective levels and counts for each category.

|  |  |  |
|-------------------------|-------------------------|-----------------------|
| ![](images/Programming%20Comfort.png) | ![](images/Statistics%20Comfort.png) | ![](images/Math%20Comfort-01.png) |

|  |  |  |
|-----------------------|--------------------------|-----------------------|
| ![](images/Prog%20Prof.png) | ![](images/Stat%20Prof-01.png) | ![](images/Math%20Prof.png) |

Next, we calculated the slope, intercept, correlation coefficient (r-value), p-value, and standard error for each of the categories and plotted them to interpret the results. Our analysis shows positive correlations between proficiency and comfort in all subjects. Programming, math, and statistics had slopes of 0.61, 0.55, and 0.8 respectively. These slopes mean that for every unit increase in reported proficiency, there is an expected x unit increase in reported comfort.

We then set up the following hypotheses:

-   H_0: There is no relationship between reported proficiency and reported comfort in a given subject.

-   H_A: There exists a relationship between reported proficiency and reported comfort in a given subject.

Correlations coefficients for programming, math, and statistics were 0.43, 0.43, and 0.6. These coefficients mean that there is a moderate positive correlation between the reported proficiency and reported comfort in a given subject. P-values for these regression lines range from 0.0015 to 0.0000018, showing statistically significant correlations at alpha values well below a = 0.01. This means we can reject the null hypothesis, and conclude that there exists a statistically significant positive correlation between the reported proficiency and reported comfort in a given subject at alpha = 0.01.

|  |  |  |
|------------------------|------------------------|------------------------|
| ![](images/Prog%20Comparison.png) | ![](images/Stat%20Comparison.png) | ![](images/Math%20Comparison.png) |
